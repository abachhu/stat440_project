{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43331cac-3282-4cb0-9d2d-e216e1fc9dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478 entries, 0 to 477\n",
      "Data columns (total 6 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   DBN                              478 non-null    object\n",
      " 1   SCHOOL NAME                      478 non-null    object\n",
      " 2   Num of SAT Test Takers           478 non-null    object\n",
      " 3   SAT Critical Reading Avg. Score  478 non-null    object\n",
      " 4   SAT Math Avg. Score              478 non-null    object\n",
      " 5   SAT Writing Avg. Score           478 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 22.5+ KB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 421 entries, 0 to 477\n",
      "Data columns (total 6 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   DBN                              421 non-null    object \n",
      " 1   SCHOOL NAME                      421 non-null    object \n",
      " 2   Num of SAT Test Takers           421 non-null    object \n",
      " 3   SAT Critical Reading Avg. Score  421 non-null    float64\n",
      " 4   SAT Math Avg. Score              421 non-null    float64\n",
      " 5   SAT Writing Avg. Score           421 non-null    float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 23.0+ KB\n",
      "None\n",
      "\n",
      "The mu is: 393.9857482185273\n",
      "The tao is: 165868.0\n",
      "The sigma^2 is: 3429.9095356040657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#  read the dataset\n",
    "df = pd.read_csv(\"2012-sat-results.csv\")\n",
    "\n",
    "print(df.info())\n",
    "print(\"\")\n",
    "\n",
    "# convert all values to numeric\n",
    "df[\"SAT Critical Reading Avg. Score\"] = pd.to_numeric(df[\"SAT Critical Reading Avg. Score\"], errors=\"coerce\")\n",
    "df[\"SAT Math Avg. Score\"] = pd.to_numeric(df[\"SAT Math Avg. Score\"], errors=\"coerce\")\n",
    "df[\"SAT Writing Avg. Score\"] = pd.to_numeric(df[\"SAT Writing Avg. Score\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df = df.dropna(subset=[\"SAT Critical Reading Avg. Score\", \"SAT Math Avg. Score\", \"SAT Writing Avg. Score\"])\n",
    "\n",
    "print(df.info())\n",
    "print(\"\")\n",
    "\n",
    "# population params\n",
    "mu = df[\"SAT Writing Avg. Score\"].mean()\n",
    "tao = df[\"SAT Writing Avg. Score\"].sum()\n",
    "sigmasq = df[\"SAT Writing Avg. Score\"].var(ddof=0)\n",
    "\n",
    "print(f\"The mu is: {mu}\")\n",
    "print(f\"The tao is: {tao}\")\n",
    "print(f\"The sigma^2 is: {sigmasq}\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4de288e-f770-4c7e-9043-c523f0e4c22a",
   "metadata": {},
   "source": [
    "# 1. Choose an auxiliary variable x that should be related to your variable of interest y. Take a SRS of size n (the same size as in Report 2)\n",
    "Our variable of interest is SAT Writing Avg. Score. A related (auxilliary) variable we are using is SAT Math Avg. Score. The SAT Math Avg. Score has a 0.8885 correlation with SAT Writing Avg. Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c31693-04fd-43a1-a971-759f9c1873ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8884561176774858"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation With an Auxilary Variable\n",
    "\n",
    "df[\"SAT Math Avg. Score\"].corr(df[\"SAT Writing Avg. Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d810bb45-26bb-41a2-b529-fb62408d6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 80\n",
    "seed = 420\n",
    "sampled_df = df.sample(n=n, replace=False, random_state=seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e310ed2f-f0ab-4799-aeb0-939e311fc28c",
   "metadata": {},
   "source": [
    "# 2. Perform a diagnostic analysis to determine if x and y have a linear relationship based on the sample data. Do regression analysis y ∼ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8d1a84-fd38-43d9-9972-c7bfda3766fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     SAT Writing Avg. Score   R-squared:                       0.858\n",
      "Model:                                OLS   Adj. R-squared:                  0.857\n",
      "Method:                     Least Squares   F-statistic:                     472.9\n",
      "Date:                    Mon, 07 Apr 2025   Prob (F-statistic):           7.54e-35\n",
      "Time:                            11:23:51   Log-Likelihood:                -362.46\n",
      "No. Observations:                      80   AIC:                             728.9\n",
      "Df Residuals:                          78   BIC:                             733.7\n",
      "Df Model:                               1                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  55.9878     15.618      3.585      0.001      24.895      87.081\n",
      "SAT Math Avg. Score     0.8211      0.038     21.746      0.000       0.746       0.896\n",
      "==============================================================================\n",
      "Omnibus:                        0.279   Durbin-Watson:                   2.197\n",
      "Prob(Omnibus):                  0.870   Jarque-Bera (JB):                0.044\n",
      "Skew:                           0.043   Prob(JB):                        0.978\n",
      "Kurtosis:                       3.077   Cond. No.                     2.54e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.54e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = sampled_df[\"SAT Math Avg. Score\"]\n",
    "y = sampled_df[\"SAT Writing Avg. Score\"]\n",
    "\n",
    "# Add a constant (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Get the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ae9634a",
   "metadata": {},
   "source": [
    "Since the p-value for the slope is 0 < 0.05, this means that you reject the null hypothesis that there is not a significant linear relationship between SAT math score and SAT writing score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "689d84b4-43d6-4311-b359-9561c8bd1a8d",
   "metadata": {},
   "source": [
    "# 3. Based on the results of the regression analysis, make a conclusion about the appropriateness of using ratio and regression estimators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9427fc4a",
   "metadata": {},
   "source": [
    "Since the p-value of the intercept is 0.001 < 0.05, this means that you reject the null hypothesis and conclude the intercept is significantly different from 0. As seen in the previous part, there is a statistically significant linear linearship between SAT math score and SAT writing scores.\n",
    "\n",
    "Both Ratio and Linear Regression estimators rely on the assumption that either μₓ or τₓ is known, which holds true for this data. However, Ratio estimators assume that the line has an intercept of 0, but this assumption is not met in this case. In contrast, the linear regression model does not require the intercept to be 0. Therefore, with this data, it is more appropriate to use the regression estimator rather than a ratio estimator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d80e87c6",
   "metadata": {},
   "source": [
    "# 4. Estimate your parameter of interest by Ratio estimator. Estimate its variance and give a confidence interval of α level chosen in Report 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f62c19c3",
   "metadata": {},
   "source": [
    "##### Calculate $\\hat \\mu_r$\n",
    "\n",
    "- $y =$ avg writing score\n",
    "- $x =$ avg math score\n",
    "- $\\alpha = .05$\n",
    "- Ratio Estimator of Population True Avg Writing Score:\n",
    "- $\\hat\\mu_r = r * \\mu_x$\n",
    "    - where $mu_x$ is population mean of $x$'s\n",
    "    - where $r$ is $\\frac{\\sum_{i=1}^n y_i}{\\sum_{i=1}^n x_i} = \\frac{\\bar y}{\\bar x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6c55662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_r_hat is: 396.1233949575724 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = .05\n",
    "mu_x = df[\"SAT Math Avg. Score\"].mean()\n",
    "r = sum(sampled_df[\"SAT Writing Avg. Score\"])/sum(sampled_df[\"SAT Math Avg. Score\"])\n",
    "mu_r_hat = r * mu_x\n",
    "print(f\"mu_r_hat is: {mu_r_hat} \\n\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b03a9cb",
   "metadata": {},
   "source": [
    "##### Estimate variance of $\\hat\\mu_r$\n",
    "- $\\hat{\\text{var}} (\\hat\\mu_r) = \\frac{N-n}{N} * s^2_r / n$\n",
    "\n",
    "- $s^2_r = \\frac{1}{n-1}\\sum_{i=1}^n (y_i - rx_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bce19091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_hat_mu_r_hat is: 6.04908217755827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = df.shape[0]\n",
    "s_r_squared = (1 / (n-1)) * sum((sampled_df[\"SAT Writing Avg. Score\"] - r * sampled_df[\"SAT Math Avg. Score\"])**2)\n",
    "var_hat_mu_r_hat = ((N-n)/N) * s_r_squared / n\n",
    "print(f\"var_hat_mu_r_hat is: {var_hat_mu_r_hat} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31f003d2",
   "metadata": {},
   "source": [
    "##### Confidence Interval\n",
    "- $100(1-\\alpha)\\%$ CI for $\\mu$ based on normal approx: $\\hat\\mu_r \\pm t_{n-1,\\frac{\\alpha}{2}}\\sqrt[]{\\hat{\\text{var}} (\\hat\\mu_r)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f10ffb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for mu_r_hat is: (391.22790616430814, 401.0188837508366) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "t_crit = t.ppf(1-(alpha/2), n-1)\n",
    "lowerBound = mu_r_hat - t_crit * np.sqrt(var_hat_mu_r_hat)\n",
    "upperBound = mu_r_hat + t_crit * np.sqrt(var_hat_mu_r_hat)\n",
    "print(f\"95% CI for mu_r_hat is: ({lowerBound}, {upperBound}) \\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f050de6",
   "metadata": {},
   "source": [
    "# 5. Estimate your parameter of interest by Regression estimator Estimate its variance and give a confidence interval of α level chosen in Report 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96fc0c0e",
   "metadata": {},
   "source": [
    "##### Calculate $\\hat\\mu_L$\n",
    "- $\\hat\\mu_L = a + b*\\mu_x$\n",
    "- $a = \\bar{y} - b * \\bar{x}$\n",
    "- $b = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8caeb0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_L_hat is: 395.4006470925351 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_bar = sampled_df[\"SAT Writing Avg. Score\"].mean()\n",
    "x_bar = sampled_df[\"SAT Math Avg. Score\"].mean()\n",
    "\n",
    "bNumerator = sum((sampled_df[\"SAT Math Avg. Score\"] - x_bar) * (sampled_df[\"SAT Writing Avg. Score\"] - y_bar))\n",
    "bDenominator = sum((sampled_df[\"SAT Math Avg. Score\"] - x_bar)**2)\n",
    "b = bNumerator / bDenominator\n",
    "\n",
    "a = y_bar - b * x_bar\n",
    "\n",
    "mu_L_hat = a + b * mu_x\n",
    "\n",
    "print(f\"mu_L_hat is: {mu_L_hat} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2666c194",
   "metadata": {},
   "source": [
    "##### Estimate Variance of $\\hat\\mu_L$\n",
    "- $\\hat{\\text{var}}(\\hat{\\mu_L}) = \\frac{N-n}{Nn(n-2)}\\sum_{i=1}^n(y_i - a - bx_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "832bda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_hat_mu_L_hat is: 5.239805102311415 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_hat_mu_L_hat = ((N - n) / (N * n * (n - 2))) * sum(((sampled_df[\"SAT Writing Avg. Score\"] - a - b * sampled_df[\"SAT Math Avg. Score\"])**2))\n",
    "print(f\"var_hat_mu_L_hat is: {var_hat_mu_L_hat} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16e36a65",
   "metadata": {},
   "source": [
    "##### Confidence Interval\n",
    "- 100(1-alpha)% CI: $\\hat{\\mu_L} \\pm t_{n-2, \\frac{\\alpha}{2}}\\sqrt[]{\\hat{\\text{var}}(\\hat{\\mu_L})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c8116d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for mu_L_hat is: (390.8434746053701, 399.95781957970013) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_crit = t.ppf(1-(alpha/2), n-2)\n",
    "lowerBound = mu_L_hat - t_crit * np.sqrt(var_hat_mu_L_hat)\n",
    "upperBound = mu_L_hat + t_crit * np.sqrt(var_hat_mu_L_hat)\n",
    "print(f\"95% CI for mu_L_hat is: ({lowerBound}, {upperBound}) \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a008f52",
   "metadata": {},
   "source": [
    "# 6. Choose the best estimator of your parameter based on estimated variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e23a5dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_hat_mu_L_hat is a better estimator of the paremeter as it has a lesser variance of 5.239805102311415\n"
     ]
    }
   ],
   "source": [
    "if var_hat_mu_r_hat > var_hat_mu_L_hat:\n",
    "    print(\"var_hat_mu_L_hat is a better estimator of the paremeter as it has a lesser variance of\", var_hat_mu_L_hat)\n",
    "else:\n",
    "    print(\"var_hat_mu_r_hat is a better estimator of the paremeter as it has a lesser variance of\", var_hat_mu_r_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3f7f3d7",
   "metadata": {},
   "source": [
    "In this case, $\\hat{\\text{var}}(\\hat{mu_L})$ is a better estimator of $\\mu$ as it has a lower variance of 5.2398, compared to the variance of 6.049 given by the ratio estimator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4469fa4e",
   "metadata": {},
   "source": [
    "# 7. Calculate the true regression coefficients.\n",
    "Namely, do regression $y ∼ x$ using whole data set (population). Is your conclusion in the part 3 changed? How does it change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "518f380d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     SAT Writing Avg. Score   R-squared:                       0.789\n",
      "Model:                                OLS   Adj. R-squared:                  0.789\n",
      "Method:                     Least Squares   F-statistic:                     1570.\n",
      "Date:                    Mon, 07 Apr 2025   Prob (F-statistic):          8.43e-144\n",
      "Time:                            11:23:51   Log-Likelihood:                -1983.0\n",
      "No. Observations:                     421   AIC:                             3970.\n",
      "Df Residuals:                         419   BIC:                             3978.\n",
      "Df Model:                               1                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  61.0737      8.504      7.182      0.000      44.359      77.789\n",
      "SAT Math Avg. Score     0.8054      0.020     39.625      0.000       0.765       0.845\n",
      "==============================================================================\n",
      "Omnibus:                      203.360   Durbin-Watson:                   1.640\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2006.342\n",
      "Skew:                          -1.817   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.058   Cond. No.                     2.71e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.71e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x = df[\"SAT Math Avg. Score\"]\n",
    "y = df[\"SAT Writing Avg. Score\"]\n",
    "\n",
    "# Add a constant (intercept)\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "# Get the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b297967",
   "metadata": {},
   "source": [
    "The true regression coefficients are $a = 61.0737$ and $b = 0.8054$. The $p$-values for the intercept and the slope are both $0$, thus we do not change our part $3$ conclusions. The assumption of linearity is met, however the regression line does not pass through $(0,0)$, thus the linear regression estimator is more appropriate to use than the ratio estimator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbcb3e21",
   "metadata": {},
   "source": [
    "# 8. Repeat steps 1-7 with another auxiliary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "822e8d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478 entries, 0 to 477\n",
      "Data columns (total 6 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   DBN                              478 non-null    object\n",
      " 1   SCHOOL NAME                      478 non-null    object\n",
      " 2   Num of SAT Test Takers           478 non-null    object\n",
      " 3   SAT Critical Reading Avg. Score  478 non-null    object\n",
      " 4   SAT Math Avg. Score              478 non-null    object\n",
      " 5   SAT Writing Avg. Score           478 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 22.5+ KB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 421 entries, 0 to 477\n",
      "Data columns (total 6 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   DBN                              421 non-null    object \n",
      " 1   SCHOOL NAME                      421 non-null    object \n",
      " 2   Num of SAT Test Takers           421 non-null    object \n",
      " 3   SAT Critical Reading Avg. Score  421 non-null    float64\n",
      " 4   SAT Math Avg. Score              421 non-null    float64\n",
      " 5   SAT Writing Avg. Score           421 non-null    float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 23.0+ KB\n",
      "None\n",
      "\n",
      "The mu is: 393.9857482185273\n",
      "The tao is: 165868.0\n",
      "The sigma^2 is: 3429.9095356040657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  read the dataset\n",
    "df = pd.read_csv(\"2012-sat-results.csv\")\n",
    "\n",
    "print(df.info())\n",
    "print(\"\")\n",
    "\n",
    "# convert all values to numeric\n",
    "df[\"SAT Critical Reading Avg. Score\"] = pd.to_numeric(df[\"SAT Critical Reading Avg. Score\"], errors=\"coerce\")\n",
    "df[\"SAT Math Avg. Score\"] = pd.to_numeric(df[\"SAT Math Avg. Score\"], errors=\"coerce\")\n",
    "df[\"SAT Writing Avg. Score\"] = pd.to_numeric(df[\"SAT Writing Avg. Score\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df = df.dropna(subset=[\"SAT Critical Reading Avg. Score\", \"SAT Math Avg. Score\", \"SAT Writing Avg. Score\"])\n",
    "\n",
    "print(df.info())\n",
    "print(\"\")\n",
    "\n",
    "# population params\n",
    "mu = df[\"SAT Writing Avg. Score\"].mean()\n",
    "tao = df[\"SAT Writing Avg. Score\"].sum()\n",
    "sigmasq = df[\"SAT Writing Avg. Score\"].var(ddof=0)\n",
    "\n",
    "print(f\"The mu is: {mu}\")\n",
    "print(f\"The tao is: {tao}\")\n",
    "print(f\"The sigma^2 is: {sigmasq}\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4c442ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.970342024638087"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our variable of interest is SAT Writing Avg. Score. A related (auxilliary) variable we are using is SAT Critical Reading Avg. Score. The SAT Critical Reading Avg. Score has a \n",
    "# 0.9703 correlation with SAT Writing Avg. Score.\n",
    "\n",
    "df[\"SAT Critical Reading Avg. Score\"].corr(df[\"SAT Writing Avg. Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7855e069-6c19-4091-9ba9-6aae2e978b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 80\n",
    "seed = 8\n",
    "sampled_df = df.sample(n=n, replace=False, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "883628c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     SAT Writing Avg. Score   R-squared:                       0.975\n",
      "Model:                                OLS   Adj. R-squared:                  0.975\n",
      "Method:                     Least Squares   F-statistic:                     3101.\n",
      "Date:                    Mon, 07 Apr 2025   Prob (F-statistic):           1.46e-64\n",
      "Time:                            11:23:52   Log-Likelihood:                -319.35\n",
      "No. Observations:                      80   AIC:                             642.7\n",
      "Df Residuals:                          78   BIC:                             647.5\n",
      "Df Model:                               1                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "const                             -16.9665      7.776     -2.182      0.032     -32.447      -1.486\n",
      "SAT Critical Reading Avg. Score     1.0236      0.018     55.685      0.000       0.987       1.060\n",
      "==============================================================================\n",
      "Omnibus:                       21.148   Durbin-Watson:                   1.923\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               32.205\n",
      "Skew:                          -1.078   Prob(JB):                     1.02e-07\n",
      "Kurtosis:                       5.238   Cond. No.                     2.22e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.22e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = sampled_df[\"SAT Critical Reading Avg. Score\"]\n",
    "y = sampled_df[\"SAT Writing Avg. Score\"]\n",
    "\n",
    "# Add a constant (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Get the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca7871-17a8-40d3-aaa2-8bfd20ee917b",
   "metadata": {},
   "source": [
    "Since the p-value for the slope is 0 < 0.05, this means that you reject the null hypothesis that there is not a significant linear relationship between SAT Critical Reading Avg. score and SAT writing Avg. score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff621ead-a246-44eb-b081-7617a0a9c121",
   "metadata": {},
   "source": [
    "# Based on the results of the regression analysis, make a conclusion about the appropriateness of using ratio and regression estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20772eb1-26af-4224-af6b-d60feaee433a",
   "metadata": {},
   "source": [
    "Since the p-value of the intercept is 0.032 < 0.05, this means that you reject the null hypothesis and conclude the intercept is significantly different from 0. As seen in the previous part, there is a statistically significant linear linearship between SAT math score and SAT writing scores.\n",
    "\n",
    "Both Ratio and Linear Regression estimators rely on the assumption that either μₓ or τₓ is known, which holds true for this data. However, Ratio estimators assume that the line has an intercept of 0, but this assumption is not met in this case. In contrast, the linear regression model does not require the intercept to be 0. Therefore, with this data, it is more appropriate to use the regression estimator rather than a ratio estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9b0ee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_r_hat is: 393.923955604779 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = .05\n",
    "mu_x = df[\"SAT Critical Reading Avg. Score\"].mean()\n",
    "r = sum(sampled_df[\"SAT Writing Avg. Score\"])/sum(sampled_df[\"SAT Critical Reading Avg. Score\"])\n",
    "mu_r_hat = r * mu_x\n",
    "print(f\"mu_r_hat is: {mu_r_hat} \\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cfd405b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_hat_mu_r_hat is: 1.872166738592592 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = df.shape[0]\n",
    "s_r_squared = (1 / (n-1)) * sum((sampled_df[\"SAT Writing Avg. Score\"] - r * sampled_df[\"SAT Critical Reading Avg. Score\"])**2)\n",
    "var_hat_mu_r_hat = ((N-n)/N) * s_r_squared / n\n",
    "print(f\"var_hat_mu_r_hat is: {var_hat_mu_r_hat} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d97b5914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for mu_r_hat is: (391.2004794256893, 396.6474317838687) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "t_crit = t.ppf(1-(alpha/2), n-1)\n",
    "lowerBound = mu_r_hat - t_crit * np.sqrt(var_hat_mu_r_hat)\n",
    "upperBound = mu_r_hat + t_crit * np.sqrt(var_hat_mu_r_hat)\n",
    "print(f\"95% CI for mu_r_hat is: ({lowerBound}, {upperBound}) \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4f2f8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_L_hat is: 393.33610086294254 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_bar = sampled_df[\"SAT Writing Avg. Score\"].mean()\n",
    "x_bar = sampled_df[\"SAT Critical Reading Avg. Score\"].mean()\n",
    "\n",
    "bNumerator = sum((sampled_df[\"SAT Critical Reading Avg. Score\"] - x_bar) * (sampled_df[\"SAT Writing Avg. Score\"] - y_bar))\n",
    "bDenominator = sum((sampled_df[\"SAT Critical Reading Avg. Score\"] - x_bar)**2)\n",
    "b = bNumerator / bDenominator\n",
    "\n",
    "a = y_bar - b * x_bar\n",
    "\n",
    "mu_L_hat = a + b * mu_x\n",
    "\n",
    "print(f\"mu_L_hat is: {mu_L_hat} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74d28451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_hat_mu_L_hat is: 1.7832087794495188 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_hat_mu_L_hat = ((N - n) / (N * n * (n - 2))) * sum(((sampled_df[\"SAT Writing Avg. Score\"] - a - b * sampled_df[\"SAT Critical Reading Avg. Score\"])**2))\n",
    "print(f\"var_hat_mu_L_hat is: {var_hat_mu_L_hat} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71ace54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for mu_L_hat is: (390.6775865862925, 395.9946151395926) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_crit = t.ppf(1-(alpha/2), n-2)\n",
    "lowerBound = mu_L_hat - t_crit * np.sqrt(var_hat_mu_L_hat)\n",
    "upperBound = mu_L_hat + t_crit * np.sqrt(var_hat_mu_L_hat)\n",
    "print(f\"95% CI for mu_L_hat is: ({lowerBound}, {upperBound}) \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd042ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_hat_mu_L_hat is a better estimator of the paremeter as it has a lesser variance of 1.7832087794495188\n"
     ]
    }
   ],
   "source": [
    "if var_hat_mu_r_hat > var_hat_mu_L_hat:\n",
    "    print(\"var_hat_mu_L_hat is a better estimator of the paremeter as it has a lesser variance of\", var_hat_mu_L_hat)\n",
    "else:\n",
    "    print(\"var_hat_mu_r_hat is a better estimator of the paremeter as it has a lesser variance of\", var_hat_mu_r_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cc13cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     SAT Writing Avg. Score   R-squared:                       0.942\n",
      "Model:                                OLS   Adj. R-squared:                  0.941\n",
      "Method:                     Least Squares   F-statistic:                     6751.\n",
      "Date:                    Mon, 07 Apr 2025   Prob (F-statistic):          1.67e-260\n",
      "Time:                            11:23:52   Log-Likelihood:                -1713.1\n",
      "No. Observations:                     421   AIC:                             3430.\n",
      "Df Residuals:                         419   BIC:                             3438.\n",
      "Df Model:                               1                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "const                              -7.5232      4.935     -1.524      0.128     -17.224       2.178\n",
      "SAT Critical Reading Avg. Score     1.0016      0.012     82.166      0.000       0.978       1.026\n",
      "==============================================================================\n",
      "Omnibus:                       50.712   Durbin-Watson:                   2.026\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              108.132\n",
      "Skew:                          -0.656   Prob(JB):                     3.31e-24\n",
      "Kurtosis:                       5.107   Cond. No.                     2.89e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.89e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x = df[\"SAT Critical Reading Avg. Score\"]\n",
    "y = df[\"SAT Writing Avg. Score\"]\n",
    "\n",
    "# Add a constant (intercept)\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "# Get the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07956b3b-586e-47d4-9a02-10164b8095c7",
   "metadata": {},
   "source": [
    "# Calculate the true regression coefficients. Namely, do regression y ∼ x using whole data set (population). Is your conclusion in the part 3 changed? How does it change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e797d-1a53-4e52-ab0e-890dfe1f8bad",
   "metadata": {},
   "source": [
    "The true regression coefficients are $a = -7.5232 $ and $b = 1.0016$. The $p$-values for the intercept is 0.128 > 0.05, do not reject the null hypothesis. This means that it is plausible that the regression line passes through $(0, 0)$. The $p$-value of the intercept is 0 < 0.05, reject the null hypothesis. This means that we can conclude there is a linear relationship between SAT Critical Reading Avg. Score and SAT Writing Avg. Score. Both Ratio and Linear Regression estimators rely on the assumption that either μₓ or τₓ is known, which holds true for this data.\n",
    "\n",
    "In part 3, we concluded one of the assumptions for Ratio Estimator was not met. This was the assumption that the regression line doesn't pass through $(0, 0)$. However, when using the whole population dataset, this assumption is met. Ratio estimator assumptions of μₓ or τₓ is known is met, passes through $(0, 0)$, and there is a linear relationship. Linear Regression estimator assumptions μₓ or τₓ is known is met, and there is a linear relationship. It would be appropriate to use either the Ratio Estimator or Linear Regression Estimator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "738ebe31",
   "metadata": {},
   "source": [
    "# 9. Based on estimation only, choose the variable that results in the most efficient estimator for parameter estimation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "770a39a5",
   "metadata": {},
   "source": [
    "I would choose SAT Critical Reading Avg. Score because it has lower variance for the ratio and regression estimators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81ead1b0",
   "metadata": {},
   "source": [
    "# 10. Based on estimation only, choose the estimator with the smallest estimated variance and ensure that the parameter falls within its confidence interval."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4abcd9b5",
   "metadata": {},
   "source": [
    "The estimator I will select is the regression estimator because it has smallest estimator of variance and mu is within the range (390.6776, 395.9946)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747e07e-e618-401d-a853-a088c2948231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
