{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43331cac-3282-4cb0-9d2d-e216e1fc9dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478 entries, 0 to 477\n",
      "Data columns (total 6 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   DBN                              478 non-null    object\n",
      " 1   SCHOOL NAME                      478 non-null    object\n",
      " 2   Num of SAT Test Takers           478 non-null    object\n",
      " 3   SAT Critical Reading Avg. Score  478 non-null    object\n",
      " 4   SAT Math Avg. Score              478 non-null    object\n",
      " 5   SAT Writing Avg. Score           478 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 22.5+ KB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 421 entries, 0 to 477\n",
      "Data columns (total 6 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   DBN                              421 non-null    object \n",
      " 1   SCHOOL NAME                      421 non-null    object \n",
      " 2   Num of SAT Test Takers           421 non-null    object \n",
      " 3   SAT Critical Reading Avg. Score  421 non-null    float64\n",
      " 4   SAT Math Avg. Score              421 non-null    float64\n",
      " 5   SAT Writing Avg. Score           421 non-null    float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 23.0+ KB\n",
      "None\n",
      "\n",
      "The mu is: 393.9857482185273\n",
      "The tao is: 165868.0\n",
      "The sigma^2 is: 3429.9095356040643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#  read the dataset\n",
    "df = pd.read_csv(\"2012-sat-results.csv\")\n",
    "\n",
    "print(df.info())\n",
    "print(\"\")\n",
    "\n",
    "# convert all values to numeric\n",
    "df[\"SAT Critical Reading Avg. Score\"] = pd.to_numeric(df[\"SAT Critical Reading Avg. Score\"], errors=\"coerce\")\n",
    "df[\"SAT Math Avg. Score\"] = pd.to_numeric(df[\"SAT Math Avg. Score\"], errors=\"coerce\")\n",
    "df[\"SAT Writing Avg. Score\"] = pd.to_numeric(df[\"SAT Writing Avg. Score\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df = df.dropna(subset=[\"SAT Critical Reading Avg. Score\", \"SAT Math Avg. Score\", \"SAT Writing Avg. Score\"])\n",
    "\n",
    "print(df.info())\n",
    "print(\"\")\n",
    "\n",
    "# population params\n",
    "mu = df[\"SAT Writing Avg. Score\"].mean()\n",
    "tao = df[\"SAT Writing Avg. Score\"].sum()\n",
    "sigmasq = df[\"SAT Writing Avg. Score\"].var(ddof=0)\n",
    "\n",
    "print(f\"The mu is: {mu}\")\n",
    "print(f\"The tao is: {tao}\")\n",
    "print(f\"The sigma^2 is: {sigmasq}\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4de288e-f770-4c7e-9043-c523f0e4c22a",
   "metadata": {},
   "source": [
    "#### Choose an auxiliary variable x that should be related to your variable of interest y. Take a SRS of size n (the same size as in Report 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c31693-04fd-43a1-a971-759f9c1873ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation With an Auxilary Variable\n",
    "# Our variable of interest is SAT Writing Avg. Score. A related variable we are using is SAT Math Avg. Score. The SAT Math Avg. Score\n",
    "# has a 0.8885 correlation with SAT Writing Avg. Score. \n",
    "df[\"SAT Math Avg. Score\"].corr(df[\"SAT Writing Avg. Score\"])\n",
    "\n",
    "n = 80\n",
    "seed = 440\n",
    "sampled_df = df.sample(n=n, replace=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310ed2f-f0ab-4799-aeb0-939e311fc28c",
   "metadata": {},
   "source": [
    "#### Perform a diagnostic analysis to determine if x and y have a linear relationship based on the sample data. Do regression analysis y ∼ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc8d1a84-fd38-43d9-9972-c7bfda3766fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     SAT Writing Avg. Score   R-squared:                       0.789\n",
      "Model:                                OLS   Adj. R-squared:                  0.789\n",
      "Method:                     Least Squares   F-statistic:                     1570.\n",
      "Date:                    Sat, 29 Mar 2025   Prob (F-statistic):          8.43e-144\n",
      "Time:                            12:50:02   Log-Likelihood:                -1983.0\n",
      "No. Observations:                     421   AIC:                             3970.\n",
      "Df Residuals:                         419   BIC:                             3978.\n",
      "Df Model:                               1                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  61.0737      8.504      7.182      0.000      44.359      77.789\n",
      "SAT Math Avg. Score     0.8054      0.020     39.625      0.000       0.765       0.845\n",
      "==============================================================================\n",
      "Omnibus:                      203.360   Durbin-Watson:                   1.640\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2006.342\n",
      "Skew:                          -1.817   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.058   Cond. No.                     2.71e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.71e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = df[\"SAT Math Avg. Score\"]\n",
    "y = df[\"SAT Writing Avg. Score\"]\n",
    "\n",
    "# Add a constant (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Get the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65780bac-a1e0-45e1-84f8-b724662190e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the p-value for the slope is 0, this means that you reject the null hypothesis and conclude there is a \n",
    "# significant linear relationship between SAT math score and SAT writing score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689d84b4-43d6-4311-b359-9561c8bd1a8d",
   "metadata": {},
   "source": [
    "#### Based on the results of the regression analysis, make a conclusion about the appropriateness of using ratio and regression estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6585ea-61d7-4eba-a68a-0745eedcbc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the p-value of the intercept is 0, this means that you reject the null hypothesis and conclude the intercept is\n",
    "# significantly different from 0. As seen in the previous part, there is a statistically significant linear linearship between \n",
    "# SAT math score and SAT writing scores. \n",
    "\n",
    "# Ratio estimators assume that the line has an intercept of 0, but this assumption is not met in this case. In contrast, the \n",
    "# linear regression model does not require the intercept to be 0. Therefore, with this data, it is more appropriate to use the \n",
    "# regression estimator rather than a ratio estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e87c6",
   "metadata": {},
   "source": [
    "# 4. Estimate your parameter of interest by Ratio estimator. Estimate its variance and give a confidence interval of α level chosen in Report 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c19c3",
   "metadata": {},
   "source": [
    "##### Calculate mu_r_hat\n",
    "\n",
    "- y = avg writing score\n",
    "- x = avg math score\n",
    "- alpha = .05\n",
    "- Ratio Estimator of Population True Avg Writing Score:\n",
    "- mu_r_hat = r * mu_x\n",
    "- where mu_x is population mean of x's\n",
    "- where r is sum from 1 to n (yi) / sum from 1 to n (xi) = ybar/xbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c55662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_r_hat is: 395.02407708915626 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = .05\n",
    "mu_x = df[\"SAT Math Avg. Score\"].mean()\n",
    "r = sum(sampled_df[\"SAT Writing Avg. Score\"])/sum(sampled_df[\"SAT Math Avg. Score\"])\n",
    "mu_r_hat = r * mu_x\n",
    "print(f\"mu_r_hat is: {mu_r_hat} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b03a9cb",
   "metadata": {},
   "source": [
    "##### Estimate variance of mu_r_hat\n",
    "\n",
    "- var_hat_mu_r_hat = ((N-n)/N) * s_r_squared\n",
    "- s_r_squared = (1 / (n-1)) * sum from 1-n (yi - r*xi)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bce19091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_hat_mu_r_hat is: 709.4558712502459 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = df.shape[0]\n",
    "s_r_squared = (1 / (n-1)) * sum((sampled_df[\"SAT Writing Avg. Score\"] - r * sampled_df[\"SAT Math Avg. Score\"])**2)\n",
    "var_hat_mu_r_hat = ((N-n)/N) * s_r_squared\n",
    "print(f\"var_hat_mu_r_hat is: {var_hat_mu_r_hat} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f003d2",
   "metadata": {},
   "source": [
    "##### Confidence Interval\n",
    "- 100(1-alpha)% CI for mu based on normal approx: mu_r_hat +- t(n-1, alpha/2) * sqrt(var_hat_mu_r_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f10ffb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for mu_r_hat is: (342.00721591635954, 448.040938261953) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "t_crit = t.ppf(1-(alpha/2), n-1)\n",
    "lowerBound = mu_r_hat - t_crit * np.sqrt(var_hat_mu_r_hat)\n",
    "upperBound = mu_r_hat + t_crit * np.sqrt(var_hat_mu_r_hat)\n",
    "print(f\"95% CI for mu_r_hat is: ({lowerBound}, {upperBound}) \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f050de6",
   "metadata": {},
   "source": [
    "# 5. Estimate your parameter of interest by Regression estimator Estimate its variance and give a confidence interval of α level chosen in Report 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc0c0e",
   "metadata": {},
   "source": [
    "##### Calculate mu_L_hat\n",
    "- mu_L_hat = a + b*mu_x\n",
    "- a = ybar - b * xbar\n",
    "- b = (sum from 1 to n ((xi - xbar) * (yi - ybar))) / (sum from 1 to n ((xi - xbar)^2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8caeb0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_L_hat is: 396.8558588854824 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_bar = sampled_df[\"SAT Writing Avg. Score\"].mean()\n",
    "x_bar = sampled_df[\"SAT Math Avg. Score\"].mean()\n",
    "\n",
    "bNumerator = sum((sampled_df[\"SAT Math Avg. Score\"] - x_bar) * (sampled_df[\"SAT Writing Avg. Score\"] - y_bar))\n",
    "bDenominator = sum((sampled_df[\"SAT Math Avg. Score\"] - x_bar)**2)\n",
    "b = bNumerator / bDenominator\n",
    "\n",
    "a = y_bar - b * x_bar\n",
    "\n",
    "mu_L_hat = a + b * mu_x\n",
    "\n",
    "print(f\"mu_L_hat is: {mu_L_hat} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666c194",
   "metadata": {},
   "source": [
    "##### Estimate Variance of mu_L_hat\n",
    "- var_hat_mu_L_hat = ((N - n)/(N * n * (n-2))) * sum from 1 to n ((yi - a - b*xi)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "832bda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_hat_mu_L_hat is: 7.678518718573295 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_hat_mu_L_hat = ((N - n) / (N * n * (n - 2))) * sum(((sampled_df[\"SAT Writing Avg. Score\"] - a - b * sampled_df[\"SAT Math Avg. Score\"])**2))\n",
    "print(f\"var_hat_mu_L_hat is: {var_hat_mu_L_hat} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e36a65",
   "metadata": {},
   "source": [
    "##### Confidence Interval\n",
    "- 100(1-alpha)% CI: mu_L_hat +- t(n-2, alpha/2) * sqrt(var_hat_mu_L_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c8116d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for mu_L_hat is: (391.3391937391112, 402.37252403185363) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_crit = t.ppf(1-(alpha/2), n-2)\n",
    "lowerBound = mu_L_hat - t_crit * np.sqrt(var_hat_mu_L_hat)\n",
    "upperBound = mu_L_hat + t_crit * np.sqrt(var_hat_mu_L_hat)\n",
    "print(f\"95% CI for mu_L_hat is: ({lowerBound}, {upperBound}) \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
