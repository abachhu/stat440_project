{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c422f1d-aa7e-449e-946b-2b0bf9032aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478 entries, 0 to 477\n",
      "Data columns (total 6 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   DBN                              478 non-null    object\n",
      " 1   SCHOOL NAME                      478 non-null    object\n",
      " 2   Num of SAT Test Takers           478 non-null    object\n",
      " 3   SAT Critical Reading Avg. Score  478 non-null    object\n",
      " 4   SAT Math Avg. Score              478 non-null    object\n",
      " 5   SAT Writing Avg. Score           478 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 22.5+ KB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 421 entries, 0 to 477\n",
      "Data columns (total 6 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   DBN                              421 non-null    object \n",
      " 1   SCHOOL NAME                      421 non-null    object \n",
      " 2   Num of SAT Test Takers           421 non-null    object \n",
      " 3   SAT Critical Reading Avg. Score  421 non-null    float64\n",
      " 4   SAT Math Avg. Score              421 non-null    float64\n",
      " 5   SAT Writing Avg. Score           421 non-null    float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 23.0+ KB\n",
      "None\n",
      "\n",
      "The mu is: 393.9857482185273\n",
      "The tao is: 165868.0\n",
      "The sigma^2 is: 3429.9095356040643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "#  read the dataset\n",
    "df = pd.read_csv(\"2012-sat-results.csv\")\n",
    "\n",
    "print(df.info())\n",
    "print(\"\")\n",
    "\n",
    "# convert all values to numeric\n",
    "df[\"SAT Critical Reading Avg. Score\"] = pd.to_numeric(df[\"SAT Critical Reading Avg. Score\"], errors=\"coerce\")\n",
    "df[\"SAT Math Avg. Score\"] = pd.to_numeric(df[\"SAT Math Avg. Score\"], errors=\"coerce\")\n",
    "df[\"SAT Writing Avg. Score\"] = pd.to_numeric(df[\"SAT Writing Avg. Score\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df = df.dropna(subset=[\"SAT Critical Reading Avg. Score\", \"SAT Math Avg. Score\", \"SAT Writing Avg. Score\"])\n",
    "\n",
    "print(df.info())\n",
    "print(\"\")\n",
    "\n",
    "# population params\n",
    "mu = df[\"SAT Writing Avg. Score\"].mean()\n",
    "tao = df[\"SAT Writing Avg. Score\"].sum()\n",
    "sigmasq = df[\"SAT Writing Avg. Score\"].var(ddof=0)\n",
    "\n",
    "print(f\"The mu is: {mu}\")\n",
    "print(f\"The tao is: {tao}\")\n",
    "print(f\"The sigma^2 is: {sigmasq}\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6199fc2c-3a61-421d-827e-7ba08badcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e65da39-8a2f-4596-8e6f-869e53dd5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making length of the DF not a prime number by randomly removing one entry\n",
    "idx = random.randint(0, len(df) - 1)\n",
    "df = df.drop(index=idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1271a873-3d6f-4ac7-b5fb-45f689a544d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu: 393.8952380952381\n",
      "Population size M: 420\n",
      "sample size n: 80\n"
     ]
    }
   ],
   "source": [
    "print(f\"mu: {df['SAT Writing Avg. Score'].mean()}\")\n",
    "print(f\"Population size M: {len(df)}\")\n",
    "print(f\"sample size n: 80\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6de63d90-3f6f-4424-9360-06267718a81c",
   "metadata": {},
   "source": [
    "## 1. Perform a systematic sample with (approximately) the same total sample size as you used in previous Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a51f592-5ce3-4c23-965d-53a47a5c62df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[378.0,\n",
       "  428.0,\n",
       "  477.0,\n",
       "  402.0,\n",
       "  416.0,\n",
       "  407.0,\n",
       "  357.0,\n",
       "  394.0,\n",
       "  356.0,\n",
       "  341.0,\n",
       "  389.0,\n",
       "  368.0,\n",
       "  388.0,\n",
       "  386.0,\n",
       "  411.0,\n",
       "  331.0,\n",
       "  395.0,\n",
       "  392.0,\n",
       "  377.0,\n",
       "  352.0],\n",
       " [628.0,\n",
       "  592.0,\n",
       "  431.0,\n",
       "  358.0,\n",
       "  404.0,\n",
       "  363.0,\n",
       "  376.0,\n",
       "  371.0,\n",
       "  414.0,\n",
       "  365.0,\n",
       "  395.0,\n",
       "  380.0,\n",
       "  351.0,\n",
       "  379.0,\n",
       "  374.0,\n",
       "  440.0,\n",
       "  318.0,\n",
       "  360.0,\n",
       "  394.0,\n",
       "  397.0],\n",
       " [362.0,\n",
       "  391.0,\n",
       "  512.0,\n",
       "  411.0,\n",
       "  367.0,\n",
       "  364.0,\n",
       "  415.0,\n",
       "  382.0,\n",
       "  317.0,\n",
       "  360.0,\n",
       "  368.0,\n",
       "  341.0,\n",
       "  359.0,\n",
       "  381.0,\n",
       "  375.0,\n",
       "  311.0,\n",
       "  382.0,\n",
       "  425.0,\n",
       "  405.0,\n",
       "  361.0],\n",
       " [359.0,\n",
       "  523.0,\n",
       "  400.0,\n",
       "  408.0,\n",
       "  398.0,\n",
       "  357.0,\n",
       "  365.0,\n",
       "  402.0,\n",
       "  352.0,\n",
       "  368.0,\n",
       "  349.0,\n",
       "  371.0,\n",
       "  358.0,\n",
       "  355.0,\n",
       "  380.0,\n",
       "  373.0,\n",
       "  380.0,\n",
       "  401.0,\n",
       "  359.0,\n",
       "  417.0]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing a 4 - in - 21 systematic sample\n",
    "\n",
    "N = 21\n",
    "n = 4\n",
    "M = len(df)\n",
    "sample_size = 80\n",
    "\n",
    "Mi = M // N # 20 groups (4 * Mi) = 80\n",
    "\n",
    "# random starting indices\n",
    "s1 = random.sample(range(N), n)\n",
    "\n",
    "# sampling from each group\n",
    "indices = [[] for _ in range(n)]\n",
    "samples = [[] for _ in range(n)]\n",
    "\n",
    "# Systematic sampling with fixed offset\n",
    "for i in range(Mi):  # for each group\n",
    "    s = [pos + i * N for pos in s1]  # apply offset to each of the starting pos\n",
    "    for j in range(n):\n",
    "        if s[j] < M:  # make sure index is within bounds\n",
    "            indices[j].append(s[j])\n",
    "            samples[j].append(df['SAT Writing Avg. Score'].iloc[s[j]])\n",
    "\n",
    "samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e447b0c-1f57-4466-8a19-0be06e800126",
   "metadata": {},
   "source": [
    "## 2. Display the indexes of your sampled units. When systematic sampling is executed correctly, the indexes of the sampled units will follow a distinct pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "475ce23a-8c02-49fb-b766-5c0cde3b732e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled units indices: [[11, 32, 53, 74, 95, 116, 137, 158, 179, 200, 221, 242, 263, 284, 305, 326, 347, 368, 389, 410], [8, 29, 50, 71, 92, 113, 134, 155, 176, 197, 218, 239, 260, 281, 302, 323, 344, 365, 386, 407], [12, 33, 54, 75, 96, 117, 138, 159, 180, 201, 222, 243, 264, 285, 306, 327, 348, 369, 390, 411], [3, 24, 45, 66, 87, 108, 129, 150, 171, 192, 213, 234, 255, 276, 297, 318, 339, 360, 381, 402]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sampled units indices:\", indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26fc3177",
   "metadata": {},
   "source": [
    "## 3. Estimate your parameter of interest by an unbiased estimator. Estimate its variance and give a confidence interval of Î± level chosen in Report 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca5e6e44",
   "metadata": {},
   "source": [
    "- $\\hat\\mu\\ = \\frac{\\hat\\tau}{M}$\n",
    "- $\\hat\\tau = N\\bar{y} = N\\sum_{i=1}^n\\frac{y_i}{n}$ where $y_i$ is the total of $y$-values in the $i$-th primary unit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7bcb0368-400b-45aa-a202-a9c8f057b6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388.7375"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yi = [sum(sample) for sample in samples]\n",
    "tau_hat = N * (sum(yi) / n)\n",
    "mu_hat = tau_hat / M\n",
    "mu_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddb92f8c",
   "metadata": {},
   "source": [
    "##### Estimated Variance\n",
    "- $\\hat{\\text{var}}(\\hat\\mu) = \\frac{1}{M^2}\\hat{\\text{var}}({\\hat\\tau})$\n",
    "- $\\hat{\\text{var}}({\\hat\\tau}) = N(N-n)\\frac{s^2_u}{n}$\n",
    "- $s^2_u = \\frac{1}{n-1} \\sum_{i=1}^n (y_i - \\bar{y})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "971c2f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.407269345238095"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bar = np.mean(yi)\n",
    "s_u_squared = np.sum((yi - y_bar) ** 2) / (n - 1)\n",
    "var_hat_tau_hat = N * (N - n) * s_u_squared / n\n",
    "var_hat_mu_hat = var_hat_tau_hat / (M ** 2)\n",
    "var_hat_mu_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4459c12",
   "metadata": {},
   "source": [
    "##### Confidence Interval of $\\alpha=0.05$\n",
    "- $\\hat\\mu \\pm t_{n-1, \\frac{\\alpha}{2}}\\sqrt{\\hat{\\text{var}}(\\hat\\mu)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebdbb0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for mu: (373.02, 404.46) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "# Confidence Interval with alpha = .05\n",
    "alpha = .05\n",
    "t_crit = t.ppf(1-(alpha/2), n-1)\n",
    "SDE = t_crit * np.sqrt(var_hat_mu_hat)\n",
    "\n",
    "CI = mu_hat - SDE, mu_hat + SDE\n",
    "print(f\"95% CI for mu: ({CI[0].round(2)}, {CI[1].round(2)}) \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ab534c4",
   "metadata": {},
   "source": [
    "# 4. Perform another systematic sampling approach, but this time, letâs change the value of $N$ that you used before. \n",
    "(As result, your $n$ will bechanged also)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1be972f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.19047619047619047\n",
      "2 0.38095238095238093\n",
      "3 0.5714285714285714\n",
      "4 0.7619047619047619\n",
      "5 0.9523809523809523\n",
      "6 1.1428571428571428\n",
      "7 1.3333333333333333\n",
      "8 1.5238095238095237\n",
      "9 1.7142857142857144\n",
      "10 1.9047619047619047\n",
      "11 2.0952380952380953\n",
      "12 2.2857142857142856\n",
      "13 2.4761904761904763\n",
      "14 2.6666666666666665\n",
      "15 2.857142857142857\n",
      "16 3.0476190476190474\n",
      "17 3.238095238095238\n",
      "18 3.428571428571429\n",
      "19 3.619047619047619\n",
      "20 3.8095238095238093\n",
      "21 4.0\n",
      "22 4.190476190476191\n",
      "23 4.380952380952381\n",
      "24 4.571428571428571\n",
      "25 4.761904761904762\n",
      "26 4.9523809523809526\n",
      "27 5.142857142857143\n",
      "28 5.333333333333333\n",
      "29 5.523809523809524\n",
      "30 5.714285714285714\n",
      "31 5.904761904761904\n",
      "32 6.095238095238095\n",
      "33 6.2857142857142865\n",
      "34 6.476190476190476\n",
      "35 6.666666666666667\n",
      "36 6.857142857142858\n",
      "37 7.047619047619048\n",
      "38 7.238095238095238\n",
      "39 7.428571428571428\n",
      "40 7.619047619047619\n",
      "41 7.809523809523809\n",
      "42 8.0\n",
      "43 8.190476190476192\n",
      "44 8.380952380952381\n",
      "45 8.571428571428571\n",
      "46 8.761904761904763\n",
      "47 8.952380952380953\n",
      "48 9.142857142857142\n",
      "49 9.333333333333334\n",
      "50 9.523809523809524\n",
      "51 9.714285714285715\n",
      "52 9.904761904761905\n",
      "53 10.095238095238095\n",
      "54 10.285714285714286\n",
      "55 10.476190476190476\n",
      "56 10.666666666666666\n",
      "57 10.857142857142858\n",
      "58 11.047619047619047\n",
      "59 11.238095238095239\n"
     ]
    }
   ],
   "source": [
    "M = 420\n",
    "for i in range(1,60):\n",
    "    n = 80 / (M / i)\n",
    "    print(i, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ff2d368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[411.0, 335.0, 442.0, 399.0, 339.0, 384.0, 369.0, 363.0, 443.0, 363.0],\n",
       " [366.0, 475.0, 345.0, 393.0, 372.0, 362.0, 411.0, 370.0, 385.0, 384.0],\n",
       " [391.0, 411.0, 364.0, 382.0, 360.0, 341.0, 381.0, 311.0, 425.0, 361.0],\n",
       " [479.0, 359.0, 326.0, 297.0, 383.0, 359.0, 373.0, 365.0, 384.0, 450.0],\n",
       " [381.0, 577.0, 383.0, 365.0, 354.0, 350.0, 359.0, 359.0, 368.0, 370.0],\n",
       " [682.0, 395.0, 375.0, 330.0, 398.0, 385.0, 333.0, 550.0, 442.0, 426.0],\n",
       " [628.0, 431.0, 404.0, 376.0, 414.0, 395.0, 351.0, 374.0, 318.0, 394.0],\n",
       " [349.0, 351.0, 370.0, 370.0, 360.0, 383.0, 393.0, 332.0, 400.0, 334.0]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing a 5 - in - 25 systematic sample\n",
    "\n",
    "N = 42\n",
    "n = 8\n",
    "M = len(df)\n",
    "sample_size = 80\n",
    "\n",
    "Mi = M // N # 20 groups (4 * Mi) = 80\n",
    "\n",
    "# random starting indices\n",
    "s1 = random.sample(range(N), n)\n",
    "\n",
    "# sampling from each group\n",
    "indices = [[] for _ in range(n)]\n",
    "samples = [[] for _ in range(n)]\n",
    "\n",
    "# Systematic sampling with fixed offset\n",
    "for i in range(Mi):  # for each group\n",
    "    s = [pos + i * N for pos in s1]  # apply offset to each of the starting pos\n",
    "    for j in range(n):\n",
    "        if s[j] < M:  # make sure index is within bounds\n",
    "            indices[j].append(s[j])\n",
    "            samples[j].append(df['SAT Writing Avg. Score'].iloc[s[j]])\n",
    "\n",
    "samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eae3ad35",
   "metadata": {},
   "source": [
    "# 5. Estimate your parameter of interest by an unbiased estimator. Estimate its variance and give a confidence interval of $\\alpha$ level chosen in Report 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bc29177",
   "metadata": {},
   "source": [
    "- $\\hat\\mu\\ = \\frac{\\hat\\tau}{M}$\n",
    "- $\\hat\\tau = N\\bar{y} = N\\sum_{i=1}^n\\frac{y_i}{n}$ where $y_i$ is the total of $y$-values in the $i$-th primary unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6988052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389.025"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yi = [sum(sample) for sample in samples]\n",
    "tau_hat = N * (sum(yi) / n)\n",
    "mu_hat = tau_hat / M\n",
    "float(mu_hat)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c09825e",
   "metadata": {},
   "source": [
    "##### Estimated Variance\n",
    "- $\\hat{\\text{var}}(\\hat\\mu) = \\frac{1}{M^2}\\hat{\\text{var}}({\\hat\\tau})$\n",
    "- $\\hat{\\text{var}}({\\hat\\tau}) = N(N-n)\\frac{s^2_u}{n}$\n",
    "- $s^2_u = \\frac{1}{n-1} \\sum_{i=1}^n (y_i - \\bar{y})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06e52274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.81758078231293"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bar = np.mean(yi)\n",
    "s_u_squared = np.sum((yi - y_bar) ** 2) / (n - 1)\n",
    "var_hat_tau_hat = N * (N - n) * s_u_squared / n\n",
    "var_hat_mu_hat = var_hat_tau_hat / (M ** 2)\n",
    "float(var_hat_mu_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5660bfb4",
   "metadata": {},
   "source": [
    "##### Confidence Interval of $\\alpha=0.05$\n",
    "- $\\hat\\mu \\pm t_{n-1, \\frac{\\alpha}{2}}\\sqrt{\\hat{\\text{var}}(\\hat\\mu)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b3369bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for mu: (372.85, 405.2) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "# Confidence Interval with alpha = .05\n",
    "alpha = .05\n",
    "t_crit = t.ppf(1-(alpha/2), n-1)\n",
    "SDE = t_crit * np.sqrt(var_hat_mu_hat)\n",
    "\n",
    "CI = mu_hat - SDE, mu_hat + SDE\n",
    "print(f\"95% CI for mu: ({CI[0].round(2)}, {CI[1].round(2)}) \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d703db8",
   "metadata": {},
   "source": [
    "# 6. Order your population with respect to y (variable of interest). Repeat steps 1-4 for the ordered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d3346f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBN</th>\n",
       "      <th>SCHOOL NAME</th>\n",
       "      <th>Num of SAT Test Takers</th>\n",
       "      <th>SAT Critical Reading Avg. Score</th>\n",
       "      <th>SAT Math Avg. Score</th>\n",
       "      <th>SAT Writing Avg. Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19K583</td>\n",
       "      <td>MULTICULTURAL HIGH SCHOOL</td>\n",
       "      <td>29</td>\n",
       "      <td>279.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17K524</td>\n",
       "      <td>INTERNATIONAL HIGH SCHOOL AT PROSPECT HEIGHTS</td>\n",
       "      <td>71</td>\n",
       "      <td>287.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09X365</td>\n",
       "      <td>ACADEMY FOR LANGUAGE AND TECHNOLOGY</td>\n",
       "      <td>54</td>\n",
       "      <td>315.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12X388</td>\n",
       "      <td>PAN AMERICAN INTERNATIONAL HIGH SCHOOL AT MONROE</td>\n",
       "      <td>30</td>\n",
       "      <td>321.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15K520</td>\n",
       "      <td>PACIFIC HIGH SCHOOL</td>\n",
       "      <td>9</td>\n",
       "      <td>352.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>10X696</td>\n",
       "      <td>HIGH SCHOOL OF AMERICAN STUDIES AT LEHMAN COLLEGE</td>\n",
       "      <td>92</td>\n",
       "      <td>636.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>31R605</td>\n",
       "      <td>STATEN ISLAND TECHNICAL HIGH SCHOOL</td>\n",
       "      <td>227</td>\n",
       "      <td>635.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>25Q525</td>\n",
       "      <td>TOWNSEND HARRIS HIGH SCHOOL</td>\n",
       "      <td>278</td>\n",
       "      <td>621.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>638.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>10X445</td>\n",
       "      <td>BRONX HIGH SCHOOL OF SCIENCE</td>\n",
       "      <td>731</td>\n",
       "      <td>632.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>02M475</td>\n",
       "      <td>STUYVESANT HIGH SCHOOL</td>\n",
       "      <td>832</td>\n",
       "      <td>679.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>682.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DBN                                        SCHOOL NAME  \\\n",
       "0    19K583                          MULTICULTURAL HIGH SCHOOL   \n",
       "1    17K524      INTERNATIONAL HIGH SCHOOL AT PROSPECT HEIGHTS   \n",
       "2    09X365                ACADEMY FOR LANGUAGE AND TECHNOLOGY   \n",
       "3    12X388   PAN AMERICAN INTERNATIONAL HIGH SCHOOL AT MONROE   \n",
       "4    15K520                                PACIFIC HIGH SCHOOL   \n",
       "..      ...                                                ...   \n",
       "415  10X696  HIGH SCHOOL OF AMERICAN STUDIES AT LEHMAN COLLEGE   \n",
       "416  31R605                STATEN ISLAND TECHNICAL HIGH SCHOOL   \n",
       "417  25Q525                        TOWNSEND HARRIS HIGH SCHOOL   \n",
       "418  10X445                       BRONX HIGH SCHOOL OF SCIENCE   \n",
       "419  02M475                             STUYVESANT HIGH SCHOOL   \n",
       "\n",
       "    Num of SAT Test Takers  SAT Critical Reading Avg. Score  \\\n",
       "0                       29                            279.0   \n",
       "1                       71                            287.0   \n",
       "2                       54                            315.0   \n",
       "3                       30                            321.0   \n",
       "4                        9                            352.0   \n",
       "..                     ...                              ...   \n",
       "415                     92                            636.0   \n",
       "416                    227                            635.0   \n",
       "417                    278                            621.0   \n",
       "418                    731                            632.0   \n",
       "419                    832                            679.0   \n",
       "\n",
       "     SAT Math Avg. Score  SAT Writing Avg. Score  \n",
       "0                  322.0                   286.0  \n",
       "1                  335.0                   291.0  \n",
       "2                  339.0                   297.0  \n",
       "3                  351.0                   298.0  \n",
       "4                  341.0                   300.0  \n",
       "..                   ...                     ...  \n",
       "415                648.0                   636.0  \n",
       "416                682.0                   636.0  \n",
       "417                651.0                   638.0  \n",
       "418                688.0                   649.0  \n",
       "419                735.0                   682.0  \n",
       "\n",
       "[420 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ordered = df.sort_values(by='SAT Writing Avg. Score').reset_index(drop=True)\n",
    "df_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "473d508b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[312.0,\n",
       "  339.0,\n",
       "  349.0,\n",
       "  354.0,\n",
       "  358.0,\n",
       "  362.0,\n",
       "  367.0,\n",
       "  370.0,\n",
       "  375.0,\n",
       "  379.0,\n",
       "  383.0,\n",
       "  388.0,\n",
       "  393.0,\n",
       "  398.0,\n",
       "  405.0,\n",
       "  414.0,\n",
       "  426.0,\n",
       "  442.0,\n",
       "  477.0,\n",
       "  587.0],\n",
       " [316.0,\n",
       "  340.0,\n",
       "  350.0,\n",
       "  354.0,\n",
       "  359.0,\n",
       "  363.0,\n",
       "  367.0,\n",
       "  370.0,\n",
       "  376.0,\n",
       "  380.0,\n",
       "  384.0,\n",
       "  388.0,\n",
       "  393.0,\n",
       "  399.0,\n",
       "  407.0,\n",
       "  416.0,\n",
       "  428.0,\n",
       "  448.0,\n",
       "  481.0,\n",
       "  592.0],\n",
       " [311.0,\n",
       "  335.0,\n",
       "  349.0,\n",
       "  354.0,\n",
       "  358.0,\n",
       "  362.0,\n",
       "  366.0,\n",
       "  370.0,\n",
       "  374.0,\n",
       "  378.0,\n",
       "  383.0,\n",
       "  387.0,\n",
       "  392.0,\n",
       "  396.0,\n",
       "  404.0,\n",
       "  414.0,\n",
       "  425.0,\n",
       "  442.0,\n",
       "  475.0,\n",
       "  570.0],\n",
       " [298.0,\n",
       "  333.0,\n",
       "  345.0,\n",
       "  352.0,\n",
       "  357.0,\n",
       "  361.0,\n",
       "  365.0,\n",
       "  369.0,\n",
       "  373.0,\n",
       "  377.0,\n",
       "  382.0,\n",
       "  385.0,\n",
       "  391.0,\n",
       "  395.0,\n",
       "  402.0,\n",
       "  411.0,\n",
       "  423.0,\n",
       "  440.0,\n",
       "  467.0,\n",
       "  533.0]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing a 4 - in - 21 systematic sample\n",
    "\n",
    "N = 21\n",
    "n = 4\n",
    "M = len(df_ordered)\n",
    "sample_size = 80\n",
    "\n",
    "Mi = M // N # 20 groups (4 * Mi) = 80\n",
    "\n",
    "# random starting indices\n",
    "s1 = random.sample(range(N), n)\n",
    "\n",
    "# sampling from each group\n",
    "indices = [[] for _ in range(n)]\n",
    "samples = [[] for _ in range(n)]\n",
    "\n",
    "# Systematic sampling with fixed offset\n",
    "for i in range(Mi):  # for each group\n",
    "    s = [pos + i * N for pos in s1]  # apply offset to each of the starting pos\n",
    "    for j in range(n):\n",
    "        if s[j] < M:  # make sure index is within bounds\n",
    "            indices[j].append(s[j])\n",
    "            samples[j].append(df_ordered['SAT Writing Avg. Score'].iloc[s[j]])\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d2b0a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled units indices: [[10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, 241, 262, 283, 304, 325, 346, 367, 388, 409], [13, 34, 55, 76, 97, 118, 139, 160, 181, 202, 223, 244, 265, 286, 307, 328, 349, 370, 391, 412], [8, 29, 50, 71, 92, 113, 134, 155, 176, 197, 218, 239, 260, 281, 302, 323, 344, 365, 386, 407], [3, 24, 45, 66, 87, 108, 129, 150, 171, 192, 213, 234, 255, 276, 297, 318, 339, 360, 381, 402]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sampled units indices:\", indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9dfbc782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392.4125"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yi = [sum(sample) for sample in samples]\n",
    "tau_hat = N * (sum(yi) / n)\n",
    "mu_hat = tau_hat / M\n",
    "mu_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef2afa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.158519345238095"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bar = np.mean(yi)\n",
    "s_u_squared = np.sum((yi - y_bar) ** 2) / (n - 1)\n",
    "var_hat_tau_hat = N * (N - n) * s_u_squared / n\n",
    "var_hat_mu_hat = var_hat_tau_hat / (M ** 2)\n",
    "var_hat_mu_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e097825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for mu: (387.74, 397.09) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "# Confidence Interval with alpha = .05\n",
    "alpha = .05\n",
    "t_crit = t.ppf(1-(alpha/2), n-1)\n",
    "SDE = t_crit * np.sqrt(var_hat_mu_hat)\n",
    "\n",
    "CI = mu_hat - SDE, mu_hat + SDE\n",
    "print(f\"95% CI for mu: ({CI[0].round(2)}, {CI[1].round(2)}) \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f46bacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.19047619047619047\n",
      "2 0.38095238095238093\n",
      "3 0.5714285714285714\n",
      "4 0.7619047619047619\n",
      "5 0.9523809523809523\n",
      "6 1.1428571428571428\n",
      "7 1.3333333333333333\n",
      "8 1.5238095238095237\n",
      "9 1.7142857142857144\n",
      "10 1.9047619047619047\n",
      "11 2.0952380952380953\n",
      "12 2.2857142857142856\n",
      "13 2.4761904761904763\n",
      "14 2.6666666666666665\n",
      "15 2.857142857142857\n",
      "16 3.0476190476190474\n",
      "17 3.238095238095238\n",
      "18 3.428571428571429\n",
      "19 3.619047619047619\n",
      "20 3.8095238095238093\n",
      "21 4.0\n",
      "22 4.190476190476191\n",
      "23 4.380952380952381\n",
      "24 4.571428571428571\n",
      "25 4.761904761904762\n",
      "26 4.9523809523809526\n",
      "27 5.142857142857143\n",
      "28 5.333333333333333\n",
      "29 5.523809523809524\n",
      "30 5.714285714285714\n",
      "31 5.904761904761904\n",
      "32 6.095238095238095\n",
      "33 6.2857142857142865\n",
      "34 6.476190476190476\n",
      "35 6.666666666666667\n",
      "36 6.857142857142858\n",
      "37 7.047619047619048\n",
      "38 7.238095238095238\n",
      "39 7.428571428571428\n",
      "40 7.619047619047619\n",
      "41 7.809523809523809\n",
      "42 8.0\n",
      "43 8.190476190476192\n",
      "44 8.380952380952381\n",
      "45 8.571428571428571\n",
      "46 8.761904761904763\n",
      "47 8.952380952380953\n",
      "48 9.142857142857142\n",
      "49 9.333333333333334\n",
      "50 9.523809523809524\n",
      "51 9.714285714285715\n",
      "52 9.904761904761905\n",
      "53 10.095238095238095\n",
      "54 10.285714285714286\n",
      "55 10.476190476190476\n",
      "56 10.666666666666666\n",
      "57 10.857142857142858\n",
      "58 11.047619047619047\n",
      "59 11.238095238095239\n"
     ]
    }
   ],
   "source": [
    "M = 420\n",
    "for i in range(1,60):\n",
    "    n = 80 / (M / i)\n",
    "    print(i, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87eac8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[330.0, 351.0, 360.0, 368.0, 377.0, 385.0, 394.0, 411.0, 433.0, 518.0],\n",
       " [326.0, 351.0, 359.0, 368.0, 376.0, 384.0, 394.0, 410.0, 431.0, 496.0],\n",
       " [311.0, 349.0, 358.0, 367.0, 375.0, 383.0, 392.0, 404.0, 425.0, 476.0],\n",
       " [302.0, 348.0, 358.0, 365.0, 374.0, 382.0, 392.0, 403.0, 424.0, 467.0],\n",
       " [318.0, 350.0, 359.0, 368.0, 376.0, 384.0, 394.0, 408.0, 430.0, 494.0],\n",
       " [339.0, 354.0, 362.0, 370.0, 379.0, 388.0, 398.0, 414.0, 442.0, 587.0],\n",
       " [312.0, 349.0, 359.0, 367.0, 375.0, 383.0, 393.0, 405.0, 426.0, 479.0],\n",
       " [335.0, 354.0, 362.0, 370.0, 379.0, 387.0, 397.0, 414.0, 442.0, 577.0]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing a 5 - in - 25 systematic sample\n",
    "\n",
    "N = 42\n",
    "n = 8\n",
    "M = len(df_ordered)\n",
    "sample_size = 80\n",
    "\n",
    "Mi = M // N # 20 groups (4 * Mi) = 80\n",
    "\n",
    "# random starting indices\n",
    "s1 = random.sample(range(N), n)\n",
    "\n",
    "# sampling from each group\n",
    "indices = [[] for _ in range(n)]\n",
    "samples = [[] for _ in range(n)]\n",
    "\n",
    "# Systematic sampling with fixed offset\n",
    "for i in range(Mi):  # for each group\n",
    "    s = [pos + i * N for pos in s1]  # apply offset to each of the starting pos\n",
    "    for j in range(n):\n",
    "        if s[j] < M:  # make sure index is within bounds\n",
    "            indices[j].append(s[j])\n",
    "            samples[j].append(df_ordered['SAT Writing Avg. Score'].iloc[s[j]])\n",
    "\n",
    "samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9c197e7",
   "metadata": {},
   "source": [
    "# 7. Choose the best estimator of your parameter based on the smallest estimated variance\n",
    "The var_hat_mu_hat from the ordered systematic sample produced a smaller estimated variance (2.158519345238095) than the periodic one. Therefore, the var_hat_mu_hat from the ordered population is better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
